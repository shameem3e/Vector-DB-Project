# ğŸ“š Vector DB Project

A minimal **local vector database system** that lets you search your **PDF** and **TXT** files using semantic meaning rather than just keywords.  
Perfect for building **local RAG (Retrieval-Augmented Generation)** prototypes and understanding how modern search works.

---

## ğŸ“Œ Features
- ğŸ“‚ Load and process **multiple PDFs/TXTs** from the `input/` folder.
- âœ‚ï¸ **Automatic text chunking** for better search accuracy.
- ğŸ¤– Use **Sentence Transformers** to generate semantic embeddings.
- âš¡ **FAISS** for fast similarity search on vectors.
- ğŸ” Search for text **by meaning**, not exact word match.
- ğŸ–¥ Works **offline** â€” no external APIs required.

---

## ğŸ“‚ Folder Structure
vector-db-project/

â”‚

â”œâ”€â”€ main.py # Runs the app: loads data, builds index, handles queries

â”œâ”€â”€ file_loader.py # Reads PDFs/TXTs and splits into text chunks

â”œâ”€â”€ vector_db.py # Builds vector database & performs similarity search

â”‚

â”œâ”€â”€ input/ # Place your PDF/TXT files here

â”‚ â”œâ”€â”€ example.pdf

â”‚ â”œâ”€â”€ notes.txt

â”‚

â”œâ”€â”€ requirements.txt # List of Python dependencies

â””â”€â”€ README.md # Project documentation


---

## âš™ï¸ Setup Guide

### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/shameem3e/Vector-DB-Project.git
cd Vector-DB-Project

```
### **2ï¸âƒ£ Create Virtual Environment**
```bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows

```
### **3ï¸âƒ£ Install Requirements**
```bash
pip install -r requirements.txt

```
### **4ï¸âƒ£ Add files**
Place your `PDF` or `TXT` files in the `input/` folder.

Example:
```bash
input/
 â”œâ”€â”€ example1.pdf
 â”œâ”€â”€ example2.txt

```
### **5ï¸âƒ£ Run the project**
```bash
python main.py

```
### **6ï¸âƒ£ Example run**
User input:
```bash
Enter your search query (or 'exit' to quit): what is machine learning

```
Output:
```bash
Top matches:
[machine_learning_notes.pdf] Machine learning is a subset of AI that focuses on algorithms learning patterns... (score: 0.4231)
[research_summary.txt] ML models are trained using data to predict future outcomes... (score: 0.4512)

```
## ğŸ“œ Code Overview
This project uses three main Python files:

### 1. `file_loader.py`
* PyMuPDF (`fitz`) â†’ Extracts text from PDF files.
* Chunking function â†’ Splits long text into smaller segments (~300 words) for better search results.

### 2. `vector_db.py`
* Sentence Transformers ([all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)) â†’ Turns text into numerical vectors (embeddings) that represent meaning.
* FAISS â†’ Stores these vectors and allows fast nearest neighbor searches to find similar chunks.

### 3. `main.py`
* Loads documents from `input/`.
* Builds a FAISS index.
* Runs a query loop so you can search your files in real time.

## â“ FAQ
Q: Why do we need chunking?

A: Without it, a query might match an entire page of irrelevant content. Smaller chunks increase relevance.

Q: Does this work without internet?

A: Yes! All models and tools run locally once installed.

Q: Can I add DOCX or HTML files?

A: Yes â€” just extend file_loader.py to handle new formats.

Q: Is this production-ready?

A: Itâ€™s a prototype for learning. For production, add persistence, error handling, and scaling features.

## ğŸ›  Tech Stack
* Python â€“ Main programming language.
* Sentence Transformers â€“ Generates semantic embeddings from text.
* FAISS â€“ Facebook AI Similarity Search for fast vector lookup.
* PyMuPDF â€“ Efficient PDF text extraction.
* NumPy â€“ Vector/matrix operations for embeddings.

## ğŸš€ Future Improvements
* ğŸ’¾ Persistence â†’ Save/load FAISS index to avoid rebuilding.
* ğŸ“„ More file types â†’ DOCX, HTML, CSV.
* ğŸ§  Integrate with LLMs for Retrieval-Augmented Generation (RAG).
* ğŸŒ Web interface using Flask or FastAPI.
* ğŸ” Advanced ranking using cosine similarity instead of L2 distance.

## ğŸ‘¨â€ğŸ’» Author
[MD. Shameem Ahammed](https://sites.google.com/view/shameem3e)

Graduate Student | AI & ML Enthusiast

---

